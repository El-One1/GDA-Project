{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaterbirdsFullData(Dataset):\n",
    "    def __init__(self, root, metadata_csv, split, transform=None):\n",
    "\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.split = 0 if split == 'train' else 1 if split == 'val' else 2\n",
    "\n",
    "        self.metadata = pd.read_csv(metadata_csv)\n",
    "\n",
    "        self.metadata = self.metadata[self.metadata['split'] == self.split]\n",
    "\n",
    "        self.classes = [d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))]\n",
    "        self.class_to_idx = {self.classes[i]: i for i in range(len(self.classes))}\n",
    "        self.idx_to_class = {i: self.classes[i] for i in range(len(self.classes))}\n",
    "\n",
    "        # Build the full samples list\n",
    "        # Map from image path to metadata row\n",
    "        self.samples = []\n",
    "        for class_name, class_idx in self.class_to_idx.items():\n",
    "            class_folder = os.path.join(root, class_name)\n",
    "            for img_filename in os.listdir(class_folder):\n",
    "                full_img_path = os.path.join(class_folder, img_filename)\n",
    "                metadata_img_filename = os.path.join(class_name, img_filename)\n",
    "\n",
    "                metadata_row = self.metadata[self.metadata['img_filename'] == metadata_img_filename]\n",
    "                if not metadata_row.empty:\n",
    "                    label = class_idx\n",
    "                    strata = metadata_row['place'].values[0]\n",
    "                    self.samples.append((full_img_path, label, strata))\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            tuple: (image, class_label, strata)\n",
    "        \"\"\"\n",
    "        img_path, label, strata = self.samples[idx]\n",
    "\n",
    "        # Load the image\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Apply transformations if provided\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, label, strata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "trainset = WaterbirdsFullData('waterbird_complete95_forest2water2', 'waterbird_complete95_forest2water2/metadata.csv', 'train', transform = transform)\n",
    "valset = WaterbirdsFullData('waterbird_complete95_forest2water2', 'waterbird_complete95_forest2water2/metadata.csv', 'val', transform = transform)\n",
    "testset = WaterbirdsFullData('waterbird_complete95_forest2water2', 'waterbird_complete95_forest2water2/metadata.csv', 'test', transform = transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=4, shuffle=True, num_workers = 4)\n",
    "valloader = DataLoader(valset, batch_size=4, shuffle=False, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50()\n",
    "model.fc = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_loss(features, labels, alpha=0.5, temperature = 0.5):\n",
    "\n",
    "    ################## LSC LOSS ##################\n",
    "\n",
    "    features = F.normalize(features, dim=1)  # Normalize features to lie on hypersphere\n",
    "\n",
    "    similarity_matrix = torch.matmul(features, features.T) / temperature\n",
    "    \n",
    "    labels = labels.unsqueeze(1)\n",
    "    positive_mask = (labels == labels.T).float()\n",
    "    negative_mask = 1 - positive_mask\n",
    "\n",
    "    exp_sim = torch.exp(similarity_matrix) * negative_mask\n",
    "    log_prob = similarity_matrix - torch.log(exp_sim.sum(dim=1, keepdim=True))\n",
    "    positive_sim = (log_prob * positive_mask).sum(dim=1) / positive_mask.sum(dim=1)\n",
    "    lsc_loss = -positive_sim.mean()\n",
    "\n",
    "    ################## LSC LOSS ##################\n",
    "\n",
    "\n",
    "\n",
    "    ################## LREP LOSS ##################\n",
    "\n",
    "    exp_positive_sim = torch.exp(similarity_matrix) \n",
    "    repel_loss_tempo = -torch.log(exp_positive_sim.diagonal() / exp_positive_sim.sum(dim=1))\n",
    "    repel_loss = repel_loss_tempo.mean()\n",
    "\n",
    "    ################## LREP LOSS ##################\n",
    "\n",
    "    return alpha * lsc_loss + (1 - alpha) * repel_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, labels, _ = next(iter(trainloader))\n",
    "loss_token = full_loss(model(input), labels)\n",
    "\n",
    "loss_token.backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
